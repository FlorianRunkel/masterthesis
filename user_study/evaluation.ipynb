{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6218302",
   "metadata": {},
   "source": [
    "# Nutzerbasierte Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d33adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/florianrunkel/Documents/02_Uni/04_Masterarbeit/masterthesis/')\n",
    "\n",
    "from backend.ml_pipe.data.database.mongodb import MongoDb\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.style.use('default')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import shapiro, kruskal, wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035fa70",
   "metadata": {},
   "source": [
    "## Retrieve Evaluation Questionnaire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393cea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '68c8349bcd07e1b6a3665a13', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 5, 5, 5, 4, 5, 3, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:45:31.111053Z'}, {'_id': '68c834ea4c8877fd37754728', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 3, 5, 5, 4, 4, 3, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:46:50.816364Z'}, {'_id': '68c8363e4c8877fd3775472a', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 4, 5, 5, 4, 3, 5, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:52:29.992306Z'}, {'_id': '68c8373dcd07e1b6a3665a15', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 5, 5, 4, 5, 5, 4, 2, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:56:45.394317Z'}, {'_id': '68c837fb4c8877fd3775472c', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 3, 5, 5, 4, 2, 2, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:59:55.437946Z'}, {'_id': '68c839ed4c8877fd3775472e', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [5, 4, 3, 4, 5, 5, 5, 5, 5, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:08:13.571931Z'}, {'_id': '68c83a87cd07e1b6a3665a17', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 5, 3, 4, 5, 5, 4, 4, 1, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:10:47.406243Z'}, {'_id': '68c83b42cd07e1b6a3665a19', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 4, 4, 3, 3, 3, 3, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:13:54.289092Z'}, {'_id': '68c844f44c8877fd37754731', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 5, 5, 5, 3, 4, 3, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:55:16.299660Z'}, {'_id': '68c8451f4c8877fd37754733', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 5, 5, 4, 4, 3, 4, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:55:58.908833Z'}, {'_id': '68c9361acd07e1b6a3665a29', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 2, 1, 4, 4, 2, 5, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-16T10:04:10.510492Z'}, {'_id': '68c93684cd07e1b6a3665a2b', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 2, 2, 2, 4, 3, 2, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T10:05:56.456814Z'}, {'_id': '68c94e4ccd07e1b6a3665a2d', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 3, 1, 2, 1, 2, 3, 2, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:47:24.524806Z'}, {'_id': '68c94ea8cd07e1b6a3665a2f', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 1, 4, 1, 3, 3, 3, 4, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:48:56.115639Z'}, {'_id': '68c94ece4c8877fd37754742', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 1, 2, 1, 1, 2, 2, 2, 1, 1], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:49:34.737312Z'}, {'_id': '68c94f7bcd07e1b6a3665a31', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 2, 1, 2, 1, 2, 1, 1, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:52:27.647452Z'}, {'_id': '68c96bf7cd07e1b6a3665a33', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 2, 2, 1, 3, 2, 2, 3, 3, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:53:58.990434Z'}, {'_id': '68c96ccdcd07e1b6a3665a35', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 3, 3, 4, 4, 3, 4, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:57:32.973094Z'}, {'_id': '68c96d204c8877fd37754744', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [5, 4, 5, 4, 5, 4, 3, 4, 4, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:58:55.946780Z'}, {'_id': '68ca81eccd07e1b6a3665a39', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 3, 3, 5, 4, 5, 5, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-17T09:39:56.756384Z'}]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mongo_client = MongoDb()\n",
    "\n",
    "    result = mongo_client.get_all('feedback')\n",
    "    feedback_data = result.get('data', [])\n",
    "\n",
    "    print(feedback_data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6157f4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statusCode': 200, 'data': [{'_id': '68c8349bcd07e1b6a3665a13', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 5, 5, 5, 4, 5, 3, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:45:31.111053Z'}, {'_id': '68c834ea4c8877fd37754728', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 3, 5, 5, 4, 4, 3, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:46:50.816364Z'}, {'_id': '68c8363e4c8877fd3775472a', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 4, 5, 5, 4, 3, 5, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:52:29.992306Z'}, {'_id': '68c8373dcd07e1b6a3665a15', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 5, 5, 4, 5, 5, 4, 2, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:56:45.394317Z'}, {'_id': '68c837fb4c8877fd3775472c', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 3, 5, 5, 4, 2, 2, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T15:59:55.437946Z'}, {'_id': '68c839ed4c8877fd3775472e', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [5, 4, 3, 4, 5, 5, 5, 5, 5, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:08:13.571931Z'}, {'_id': '68c83a87cd07e1b6a3665a17', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 5, 3, 4, 5, 5, 4, 4, 1, 5], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:10:47.406243Z'}, {'_id': '68c83b42cd07e1b6a3665a19', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 4, 4, 4, 4, 3, 3, 3, 3, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:13:54.289092Z'}, {'_id': '68c844f44c8877fd37754731', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 5, 5, 5, 3, 4, 3, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:55:16.299660Z'}, {'_id': '68c8451f4c8877fd37754733', 'uid': 'UID001', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 5, 4, 5, 5, 4, 4, 3, 4, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-15T16:55:58.908833Z'}, {'_id': '68c9361acd07e1b6a3665a29', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 2, 1, 4, 4, 2, 5, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-16T10:04:10.510492Z'}, {'_id': '68c93684cd07e1b6a3665a2b', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 2, 2, 2, 4, 3, 2, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T10:05:56.456814Z'}, {'_id': '68c94e4ccd07e1b6a3665a2d', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 3, 1, 2, 1, 2, 3, 2, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:47:24.524806Z'}, {'_id': '68c94ea8cd07e1b6a3665a2f', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 1, 4, 1, 3, 3, 3, 4, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:48:56.115639Z'}, {'_id': '68c94ece4c8877fd37754742', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 1, 2, 1, 1, 2, 2, 2, 1, 1], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:49:34.737312Z'}, {'_id': '68c94f7bcd07e1b6a3665a31', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 2, 1, 2, 1, 2, 1, 1, 2, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T11:52:27.647452Z'}, {'_id': '68c96bf7cd07e1b6a3665a33', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [3, 2, 2, 1, 3, 2, 2, 3, 3, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:53:58.990434Z'}, {'_id': '68c96ccdcd07e1b6a3665a35', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 3, 3, 4, 4, 3, 4, 3], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:57:32.973094Z'}, {'_id': '68c96d204c8877fd37754744', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [5, 4, 5, 4, 5, 4, 3, 4, 4, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-16T13:58:55.946780Z'}, {'_id': '68ca81eccd07e1b6a3665a39', 'uid': 'UID002', 'freeText': '', 'prognoseBewertung': [{'modell': '', 'prognose': '', 'echt': '', 'bemerkung': ''}], 'bewertungsskala': [4, 4, 4, 3, 3, 5, 4, 5, 5, 4], 'explanationFeedback': {}, 'timestamp': '2025-09-17T09:39:56.756384Z'}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYMONGO_DISABLE_IPV6\"] = \"1\"     # IPv6 erstmal ausschalten\n",
    "os.environ[\"DNSPYTHON_IPV6\"] = \"false\"\n",
    "\n",
    "import dns.resolver\n",
    "r = dns.resolver.Resolver(configure=True)\n",
    "r.nameservers = [\"1.1.1.1\", \"8.8.8.8\"]       # Router-DNS umgehen\n",
    "r.timeout = 2.0\n",
    "r.lifetime = 3.0\n",
    "dns.resolver.default_resolver = r            # global setzen\n",
    "\n",
    "# jetzt erst Deinen Code:\n",
    "mongo_client = MongoDb()\n",
    "result = mongo_client.get_all(\"feedback\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605cdf7",
   "metadata": {},
   "source": [
    "##  Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be81858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Feedback entries loaded\n",
      "\n",
      "Bewertungsskala-Längen:\n",
      "rating_length\n",
      "10    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FEEDBACK-DATA OVERVIEW\n",
      "==================================================\n",
      "Total number of feedback: 20\n",
      "Control Group (10 Fragen): 10 Teilnehmer\n",
      "Experimental Group (10 Fragen): 10 Teilnehmer\n",
      "\n",
      "FIRST 3 ROWS:\n",
      "   uid        group  rating_length\n",
      "UID001 Experimental             10\n",
      "UID001 Experimental             10\n",
      "UID001 Experimental             10\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Error handling getting feedback data.\n",
    "'''\n",
    "if result and 'data' in result:\n",
    "    feedback_data = result['data']\n",
    "    print(f\"{len(feedback_data)} Feedback entries loaded\")\n",
    "else:\n",
    "    print(\"No data available\")\n",
    "    feedback_data = []\n",
    "\n",
    "'''\n",
    "Create a dataframe from the feedback data and overview.\n",
    "'''\n",
    "if len(feedback_data) > 0:\n",
    "    df = pd.DataFrame(feedback_data)\n",
    "\n",
    "    df['rating_length'] = df['bewertungsskala'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    print(f\"\\nBewertungsskala-Längen:\")\n",
    "    print(df['rating_length'].value_counts().sort_index())\n",
    "\n",
    "    '''\n",
    "    Infer the group of the feedback data.\n",
    "    '''\n",
    "    def infer_group(row):\n",
    "        uid = str(row.get('uid', '')).lower()\n",
    "        rl = row['rating_length']\n",
    "        if uid.startswith('uid001'):\n",
    "            return 'Experimental'\n",
    "        if uid.startswith('uid002') or uid.startswith('uui2'):\n",
    "            return 'Control'\n",
    "\n",
    "        return 'Unknown'\n",
    "\n",
    "    df['group'] = df.apply(infer_group, axis=1)\n",
    "\n",
    "    MAX_ITEMS = 10\n",
    "    for i in range(MAX_ITEMS):\n",
    "        df[f'rating_{i+1}'] = df.apply(\n",
    "            lambda row: row['bewertungsskala'][i]\n",
    "            if isinstance(row['bewertungsskala'], list) and len(row['bewertungsskala']) > i\n",
    "            else np.nan,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # Teilmengen\n",
    "    control_df = df[df['group'] == 'Control'].copy()\n",
    "    experimental_df = df[df['group'] == 'Experimental'].copy()\n",
    "    unknown_df = df[df['group'] == 'Unknown'].copy()\n",
    "\n",
    "    # Grundlegende Statistiken\n",
    "    print(\"\\nFEEDBACK-DATA OVERVIEW\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total number of feedback: {len(df)}\")\n",
    "    print(f\"Control Group (10 Fragen): {len(control_df)} Teilnehmer\")\n",
    "    print(f\"Experimental Group (10 Fragen): {len(experimental_df)} Teilnehmer\")\n",
    "\n",
    "    if len(unknown_df) > 0:\n",
    "        print(\"\\nNote: There are entries with unknown group (missing/ambiguous UID). Examples:\")\n",
    "        cols_show = ['uid', 'rating_length']\n",
    "        print(unknown_df[cols_show].head(5).to_string(index=False))\n",
    "\n",
    "    # Erste Zeilen\n",
    "    print(f\"\\nFIRST 3 ROWS:\")\n",
    "    cols_preview = ['uid', 'group', 'rating_length']\n",
    "    print(df[cols_preview].head(3).to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"No data available for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f392a3e",
   "metadata": {},
   "source": [
    "## Statistical Comparisons of Both Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18292073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPREHENSIBILITY & INTERPRETABILITY:\n",
      "--------------------------------------------------------------------------------\n",
      "  Control Group:    M = 3.55, n = 20\n",
      "  Experimental Group: M = 4.10, n = 20\n",
      "  Mann-Whitney-U:   U = 140.000, p = 0.072\n",
      "  Cohen's d:        d = -0.673\n",
      "  → NOT SIGNIFICANT: No differences (p ≥ 0.05)\n",
      "\n",
      "CONFIDENCE IN PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Control Group:    M = 2.50, n = 20\n",
      "  Experimental Group: M = 4.05, n = 20\n",
      "  Mann-Whitney-U:   U = 69.000, p = 0.000\n",
      "  Cohen's d:        d = -1.551\n",
      "  → SIGNIFICANT: Control Group is lower (p < 0.05)\n",
      "\n",
      "USABILITY FOR RECRUITING:\n",
      "--------------------------------------------------------------------------------\n",
      "  Control Group:    M = 2.65, n = 20\n",
      "  Experimental Group: M = 4.75, n = 20\n",
      "  Mann-Whitney-U:   U = 36.000, p = 0.000\n",
      "  Cohen's d:        d = -2.092\n",
      "  → SIGNIFICANT: Control Group is lower (p < 0.05)\n",
      "\n",
      "INTEGRATION OF HUMAN EXPERTISE AND AI SUPPORT:\n",
      "--------------------------------------------------------------------------------\n",
      "  Control Group:    M = 2.80, n = 20\n",
      "  Experimental Group: M = 3.85, n = 20\n",
      "  Mann-Whitney-U:   U = 89.500, p = 0.002\n",
      "  Cohen's d:        d = -1.143\n",
      "  → SIGNIFICANT: Control Group is lower (p < 0.05)\n",
      "\n",
      "PERCEIVED VALUE & INTENTION TO USE:\n",
      "--------------------------------------------------------------------------------\n",
      "  Control Group:    M = 3.15, n = 20\n",
      "  Experimental Group: M = 3.80, n = 20\n",
      "  Mann-Whitney-U:   U = 135.000, p = 0.072\n",
      "  Cohen's d:        d = -0.571\n",
      "  → NOT SIGNIFICANT: No differences (p ≥ 0.05)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF ALL COMPARISONS:\n",
      "================================================================================\n",
      "Significant Differences: 3/5 Categories\n",
      "\n",
      "Significant Categories:\n",
      "  • Confidence in Predictions: Control Group is lower (p = 0.000, d = -1.551, large)\n",
      "  • Usability for Recruiting: Control Group is lower (p = 0.000, d = -2.092, large)\n",
      "  • Integration of Human Expertise and AI Support: Control Group is lower (p = 0.002, d = -1.143, large)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define the questions for the control and experimental group.\n",
    "'''\n",
    "\n",
    "# Group A Questions\n",
    "control_group_questions = [\n",
    "    \"The system's predictions about candidate job-switching readiness seemed realistic.\",\n",
    "    \"The predictions were relevant for prioritizing candidates in Active Sourcing.\",\n",
    "    \"I trusted the system's predictions when deciding which candidates to approach.\",\n",
    "    \"The recommendations gave me enough confidence to base sourcing decisions on them.\",\n",
    "    \"The system's predictions were easy to interpret without further explanation.\",\n",
    "    \"The predictions helped me to structure the candidate selection process more efficiently.\",\n",
    "    \"The system's predictions supported me in combining them with my own recruiting expertise.\",\n",
    "    \"The system turned out to be a valuable complement to my own judgment.\",\n",
    "    \"I can imagine using such a prediction system in my daily recruiting activities.\",\n",
    "    \"The system would help me to improve the effectiveness of my sourcing decisions.\"\n",
    "]\n",
    "\n",
    "# Group B Questions\n",
    "experimental_group_questions = [\n",
    "    \"The explanations made it clear why a candidate was predicted as more or less likely to switch jobs.\",\n",
    "    \"The explanations increased my understanding of how the system generated its predictions.\",\n",
    "    \"The explanations strengthened my confidence in the reliability of the predictions.\",\n",
    "    \"The presence of explanations made me more willing to act on the system's recommendations.\",\n",
    "    \"The combination of predictions and explanations was straightforward and clear to understand.\",\n",
    "    \"The explanations improved my ability to identify which candidates should be prioritized in Active Sourcing.\",\n",
    "    \"The explanations supported me in combining the system's predictions with my own recruiting expertise.\",\n",
    "    \"The system turned out to be a valuable complement to my own judgment.\",\n",
    "    \"I could imagine integrating such a system with explanations into my daily recruiting workflow.\",\n",
    "    \"The explanations provided added value compared to predictions alone.\"\n",
    "]\n",
    "\n",
    "'''\n",
    "Define comparable questions\n",
    "'''\n",
    "comparable_questions = {\n",
    "    \"Comprehensibility & Interpretability\": {\n",
    "        \"control\": [1, 2],     # Q1–Q2\n",
    "        \"experimental\": [1, 2] # Q1–Q2\n",
    "    },\n",
    "    \"Confidence in Predictions\": {\n",
    "        \"control\": [3, 4],     # Q3–Q4\n",
    "        \"experimental\": [3, 4] # Q3–Q4\n",
    "    },\n",
    "    \"Usability for Recruiting\": {\n",
    "        \"control\": [5, 6],     # Q5–Q6\n",
    "        \"experimental\": [5, 6] # Q5–Q6\n",
    "    },\n",
    "    \"Integration of Human Expertise and AI Support\": {\n",
    "        \"control\": [7, 8],     # Q7–Q8\n",
    "        \"experimental\": [7, 8] # Q7–Q8\n",
    "    },\n",
    "    \"Perceived Value & Intention to Use\": {\n",
    "        \"control\": [9, 10],    # Q9–Q10\n",
    "        \"experimental\": [9, 10]# Q9–Q10\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "Compare the control and experimental group.\n",
    "'''\n",
    "comparison_results = []\n",
    "\n",
    "for category, question_indices in comparable_questions.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    control_ratings = []\n",
    "    for idx in question_indices['control']:\n",
    "        col = f'rating_{idx}'\n",
    "        if col in control_df.columns:\n",
    "            ratings = control_df[col].dropna()\n",
    "            control_ratings.extend(ratings.tolist())\n",
    "\n",
    "    experimental_ratings = []\n",
    "    for idx in question_indices['experimental']:\n",
    "        col = f'rating_{idx}'\n",
    "        if col in experimental_df.columns:\n",
    "            ratings = experimental_df[col].dropna()\n",
    "            experimental_ratings.extend(ratings.tolist())\n",
    "\n",
    "    '''\n",
    "    Perform the Mann-Whitney-U test.\n",
    "    '''\n",
    "    if len(control_ratings) > 0 and len(experimental_ratings) > 0:\n",
    "\n",
    "        stat, p_value = mannwhitneyu(control_ratings, experimental_ratings, alternative='two-sided')\n",
    "\n",
    "        # Effect size (Cohen's d)\n",
    "        n1, n2 = len(control_ratings), len(experimental_ratings)\n",
    "        pooled_std = np.sqrt(((n1-1)*np.var(control_ratings) + (n2-1)*np.var(experimental_ratings)) / (n1+n2-2))\n",
    "        cohens_d = (np.mean(control_ratings) - np.mean(experimental_ratings)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "        result = {\n",
    "            'category': category,\n",
    "            'control_mean': np.mean(control_ratings),\n",
    "            'experimental_mean': np.mean(experimental_ratings),\n",
    "            'control_n': len(control_ratings),\n",
    "            'experimental_n': len(experimental_ratings),\n",
    "            'u_statistic': stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "        comparison_results.append(result)\n",
    "\n",
    "        print(f\"  Control Group:    M = {result['control_mean']:.2f}, n = {result['control_n']}\")\n",
    "        print(f\"  Experimental Group: M = {result['experimental_mean']:.2f}, n = {result['experimental_n']}\")\n",
    "        print(f\"  Mann-Whitney-U:   U = {stat:.3f}, p = {p_value:.3f}\")\n",
    "        print(f\"  Cohen's d:        d = {cohens_d:.3f}\")\n",
    "    \n",
    "        if p_value < 0.05:\n",
    "            direction = \"higher\" if result['control_mean'] > result['experimental_mean'] else \"lower\"\n",
    "            print(f\"  → SIGNIFICANT: Control Group is {direction} (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  → NOT SIGNIFICANT: No differences (p ≥ 0.05)\")\n",
    "    else:\n",
    "        print(f\"  → NOT ENOUGH DATA FOR COMPARISON\")\n",
    "\n",
    "'''\n",
    "Summarize the comparison results.\n",
    "'''\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"SUMMARY OF ALL COMPARISONS:\")\n",
    "print(\"=\" * 80)\n",
    "significant_count = sum(1 for r in comparison_results if r['significant'])\n",
    "print(f\"Significant Differences: {significant_count}/{len(comparison_results)} Categories\")\n",
    "\n",
    "if significant_count > 0:\n",
    "    print(f\"\\nSignificant Categories:\")\n",
    "    for result in comparison_results:\n",
    "        if result['significant']:\n",
    "            direction = \"higher\" if result['control_mean'] > result['experimental_mean'] else \"lower\"\n",
    "            effect_size = \"large\" if abs(result['cohens_d']) > 0.8 else \"medium\" if abs(result['cohens_d']) > 0.5 else \"small\"\n",
    "            print(f\"  • {result['category']}: Control Group is {direction} (p = {result['p_value']:.3f}, d = {result['cohens_d']:.3f}, {effect_size})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6edd871",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cfe47b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONTROL GROUP NORMALITY TESTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Question  N  Shapiro-W  p-Value Normal Distributed\n",
      "      Q1 10     0.7516   0.0037                 No\n",
      "      Q2 10     0.7404   0.0027                 No\n",
      "      Q3 10     0.8526   0.0623                Yes\n",
      "      Q4 10     0.8917   0.1770                Yes\n",
      "      Q5 10     0.7957   0.0129                 No\n",
      "      Q6 10     0.8250   0.0291                 No\n",
      "      Q7 10     0.8858   0.1520                Yes\n",
      "      Q8 10     0.9165   0.3283                Yes\n",
      "      Q9 10     0.9073   0.2632                Yes\n",
      "     Q10 10     0.7432   0.0029                 No\n",
      "\n",
      "EXPERIMENTAL GROUP NORMALITÄTSTESTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Question  N  Shapiro-W  p-Value Normal Distributed\n",
      "      Q1 10     0.8022   0.0154                 No\n",
      "      Q2 10     0.6553   0.0003                 No\n",
      "      Q3 10     0.7516   0.0037                 No\n",
      "      Q4 10     0.8197   0.0251                 No\n",
      "      Q5 10     0.5093   0.0000                 No\n",
      "      Q6 10     0.5316   0.0000                 No\n",
      "      Q7 10     0.8148   0.0219                 No\n",
      "      Q8 10     0.9108   0.2869                Yes\n",
      "      Q9 10     0.9240   0.3915                Yes\n",
      "     Q10 10     0.6553   0.0003                 No\n",
      "\n",
      "TOTAL INTERPRETATION: 13/20 Questions are not normally distributed\n",
      "→ Non-parametric tests (like the Kruskal-Wallis) are appropriate\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCONTROL GROUP NORMALITY TESTS:\")\n",
    "print(\"-\" * 80)\n",
    "control_normality_results = []\n",
    "for i, question in enumerate(control_group_questions):\n",
    "    col = f'rating_{i+1}'\n",
    "    if col in control_df.columns:\n",
    "        ratings = control_df[col].dropna()\n",
    "        if len(ratings) >= 3:\n",
    "            stat, p_value = shapiro(ratings)\n",
    "            control_normality_results.append({\n",
    "                'Question': f\"Q{i+1}\",\n",
    "                'N': len(ratings),\n",
    "                'Shapiro-W': round(stat, 4),\n",
    "                'p-Value': round(p_value, 4),\n",
    "                'Normal Distributed': 'Yes' if p_value > 0.05 else 'No'\n",
    "            })\n",
    "\n",
    "if control_normality_results:\n",
    "    control_normality_df = pd.DataFrame(control_normality_results)\n",
    "    print(control_normality_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No Control Group Data available\")\n",
    "\n",
    "print(\"\\nEXPERIMENTAL GROUP NORMALITÄTSTESTS:\")\n",
    "print(\"-\" * 80)\n",
    "experimental_normality_results = []\n",
    "for i, question in enumerate(experimental_group_questions):\n",
    "    col = f'rating_{i+1}'\n",
    "    if col in experimental_df.columns:\n",
    "        ratings = experimental_df[col].dropna()\n",
    "        if len(ratings) >= 3:\n",
    "            stat, p_value = shapiro(ratings)\n",
    "            experimental_normality_results.append({\n",
    "                'Question': f\"Q{i+1}\",\n",
    "                'N': len(ratings),\n",
    "                'Shapiro-W': round(stat, 4),\n",
    "                'p-Value': round(p_value, 4),\n",
    "                'Normal Distributed': 'Yes' if p_value > 0.05 else 'No'\n",
    "            })\n",
    "\n",
    "if experimental_normality_results:\n",
    "    experimental_normality_df = pd.DataFrame(experimental_normality_results)\n",
    "    print(experimental_normality_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No Experimental Group Data available\")\n",
    "\n",
    "'''\n",
    "Summarize the normality results.\n",
    "'''\n",
    "all_normality_results = control_normality_results + experimental_normality_results\n",
    "non_normal_count = sum(1 for result in all_normality_results if result['Normal Distributed'] == 'No')\n",
    "print(f\"\\nTOTAL INTERPRETATION: {non_normal_count}/{len(all_normality_results)} Questions are not normally distributed\")\n",
    "print(\"→ Non-parametric tests (like the Kruskal-Wallis) are appropriate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "469064b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Construct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Control</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Experimental</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprehensibility &amp; Interpretability</td>\n",
       "      <td>3.550</td>\n",
       "      <td>0.798</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Confidence in Predictions</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.080</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Usability for Recruiting</td>\n",
       "      <td>2.650</td>\n",
       "      <td>1.081</td>\n",
       "      <td>4.750</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integration of Human Expertise and AI Support</td>\n",
       "      <td>2.800</td>\n",
       "      <td>0.949</td>\n",
       "      <td>3.850</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceived Value &amp; Intention to Use</td>\n",
       "      <td>3.150</td>\n",
       "      <td>1.081</td>\n",
       "      <td>3.800</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Construct Control        Experimental  \\\n",
       "                                                    Mean     SD         Mean   \n",
       "0           Comprehensibility & Interpretability   3.550  0.798        4.100   \n",
       "1                      Confidence in Predictions   2.500  1.080        4.050   \n",
       "2                       Usability for Recruiting   2.650  1.081        4.750   \n",
       "3  Integration of Human Expertise and AI Support   2.800  0.949        3.850   \n",
       "4             Perceived Value & Intention to Use   3.150  1.081        3.800   \n",
       "\n",
       "          \n",
       "      SD  \n",
       "0  0.459  \n",
       "1  0.550  \n",
       "2  0.486  \n",
       "3  0.669  \n",
       "4  0.753  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Build the scores for the control and experimental group.\n",
    "'''\n",
    "def build_scores(df, question_texts, comparable_questions, side_key, agg=\"mean\"):\n",
    "    q_to_col = {f\"Q{i+1}\": f\"rating_{i+1}\" for i in range(len(question_texts))}\n",
    "    out = {}\n",
    "    for cat, sides in comparable_questions.items():\n",
    "        idxs = sides.get(side_key, [])\n",
    "        cols = [q_to_col.get(f\"Q{i}\") for i in idxs]\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "        if not cols:\n",
    "            continue\n",
    "        block = df[cols]\n",
    "        out[cat] = block.mean(axis=1) if agg == \"mean\" else block.median(axis=1)\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "'''\n",
    "Summarize the means and standard deviations of the control and experimental group.\n",
    "'''\n",
    "def summarize_means_sd(control_df, experimental_df, control_qs, experimental_qs, comparable_questions, agg=\"mean\"):\n",
    "    ctrl = build_scores(control_df, control_qs, comparable_questions, \"control\", agg=agg)\n",
    "    exp  = build_scores(experimental_df, experimental_qs, comparable_questions, \"experimental\", agg=agg)\n",
    "\n",
    "    dims = [c for c in comparable_questions.keys() if c in ctrl.columns and c in exp.columns]\n",
    "    rows = []\n",
    "    for d in dims:\n",
    "        x, y = ctrl[d].values, exp[d].values\n",
    "        rows.append({\n",
    "            \"Construct\": d,\n",
    "            \"Control_Mean\": np.nanmean(x),\n",
    "            \"Control_SD\":   np.nanstd(x, ddof=1),\n",
    "            \"Experimental_Mean\": np.nanmean(y),\n",
    "            \"Experimental_SD\":   np.nanstd(y, ddof=1),\n",
    "        })\n",
    "    df_sum = pd.DataFrame(rows)\n",
    "\n",
    "    cols = pd.MultiIndex.from_tuples(\n",
    "        [(\"Construct\",\"\"),\n",
    "         (\"Control\",\"Mean\"), (\"Control\",\"SD\"),\n",
    "         (\"Experimental\",\"Mean\"), (\"Experimental\",\"SD\")],\n",
    "        names=[\"\", \"\"]\n",
    "    )\n",
    "    data = []\n",
    "    for _, r in df_sum.iterrows():\n",
    "        data.append([\n",
    "            r[\"Construct\"],\n",
    "            r[\"Control_Mean\"], r[\"Control_SD\"],\n",
    "            r[\"Experimental_Mean\"], r[\"Experimental_SD\"]\n",
    "        ])\n",
    "    table = pd.DataFrame(data, columns=cols)\n",
    "    table[(\"Control\",\"Mean\")] = table[(\"Control\",\"Mean\")].map(lambda v: f\"{v:.3f}\")\n",
    "    table[(\"Control\",\"SD\")]   = table[(\"Control\",\"SD\")].map(lambda v: f\"{v:.3f}\")\n",
    "    table[(\"Experimental\",\"Mean\")] = table[(\"Experimental\",\"Mean\")].map(lambda v: f\"{v:.3f}\")\n",
    "    table[(\"Experimental\",\"SD\")]   = table[(\"Experimental\",\"SD\")].map(lambda v: f\"{v:.3f}\")\n",
    "    return table\n",
    "\n",
    "'''\n",
    "Build the table for the control and experimental group.\n",
    "'''\n",
    "paper_table = summarize_means_sd(\n",
    "    control_df, experimental_df,\n",
    "    control_group_questions, experimental_group_questions,\n",
    "    comparable_questions, agg=\"mean\"\n",
    ")\n",
    "\n",
    "display(paper_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3c323",
   "metadata": {},
   "source": [
    "## Mann-Whitney-U-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "076a34c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Median (Control)</th>\n",
       "      <th>Median (Experimental)</th>\n",
       "      <th>U</th>\n",
       "      <th>p</th>\n",
       "      <th>Cliff's Δ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprehensibility &amp; Interpretability</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Confidence in Predictions</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Usability for Recruiting</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integration of Human Expertise and AI Support</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceived Value &amp; Intention to Use</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Dimension  Median (Control)  \\\n",
       "0           Comprehensibility & Interpretability              4.00   \n",
       "1                      Confidence in Predictions              2.25   \n",
       "2                       Usability for Recruiting              2.50   \n",
       "3  Integration of Human Expertise and AI Support              2.75   \n",
       "4             Perceived Value & Intention to Use              3.25   \n",
       "\n",
       "   Median (Experimental)     U       p  Cliff's Δ  \n",
       "0                   4.25  29.0  0.1069       0.42  \n",
       "1                   4.00  11.5  0.0033       0.77  \n",
       "2                   5.00   3.5  0.0004       0.93  \n",
       "3                   3.75  17.0  0.0126       0.66  \n",
       "4                   3.75  32.0  0.1799       0.36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Calculate the cliffs delta (Δ)\n",
    "'''\n",
    "def cliffs_delta(x, y):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return np.nan\n",
    "    greater, less = 0, 0\n",
    "    for xi in x:\n",
    "        greater += np.sum(xi > y)\n",
    "        less    += np.sum(xi < y)\n",
    "    n_pairs = len(x) * len(y)\n",
    "    if n_pairs == 0:\n",
    "        return np.nan\n",
    "    return (greater - less) / n_pairs\n",
    "\n",
    "'''\n",
    "Build the dimension scores for the control and experimental group\n",
    "'''\n",
    "mapping = {\n",
    "    \"Comprehensibility & Interpretability\": {\"Control\": [1, 2], \"Experimental\": [1, 2]},\n",
    "    \"Confidence in Predictions\":            {\"Control\": [3, 4], \"Experimental\": [3, 4]},\n",
    "    \"Usability for Recruiting\":             {\"Control\": [5, 6], \"Experimental\": [5, 6]},\n",
    "    \"Integration of Human Expertise and AI Support\": {\"Control\": [7, 8], \"Experimental\": [7, 8]},\n",
    "    \"Perceived Value & Intention to Use\":   {\"Control\": [9, 10], \"Experimental\": [9, 10]},\n",
    "}\n",
    "\n",
    "'''\n",
    "Build the dimension scores for the control and experimental grou\n",
    "'''\n",
    "def build_dimension_scores(df, mapping, group_col=\"group\"):\n",
    "    df = df.copy()\n",
    "    if \"participant_id\" not in df.columns:\n",
    "        df[\"participant_id\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        g = row[group_col]\n",
    "        pid = row[\"participant_id\"]\n",
    "        for dim, m in mapping.items():\n",
    "            idxs = m.get(g, [])\n",
    "            cols = [f\"rating_{i}\" for i in idxs if f\"rating_{i}\" in df.columns]\n",
    "            vals = [row[c] for c in cols if pd.notnull(row[c])]\n",
    "            score = np.mean(vals) if len(vals) == 2 else np.nan\n",
    "            rows.append({\"participant_id\": pid, \"group\": g, \"dimension\": dim, \"score\": score})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "'''\n",
    "Perform the Mann-Whitney-U-Test\n",
    "'''\n",
    "def mwu_test(df, mapping, alpha=0.05):\n",
    "    long_df = build_dimension_scores(df, mapping, group_col=\"group\")\n",
    "\n",
    "    rows = []\n",
    "    for dim in mapping.keys():\n",
    "        a = long_df[(long_df[\"dimension\"] == dim) & (long_df[\"group\"] == \"Control\")][\"score\"].dropna()\n",
    "        b = long_df[(long_df[\"dimension\"] == dim) & (long_df[\"group\"] == \"Experimental\")][\"score\"].dropna()\n",
    "\n",
    "        if len(a) == 0 or len(b) == 0:\n",
    "            rows.append({\n",
    "                \"Dimension\": dim, \"n_Control\": len(a), \"n_Experimental\": len(b),\n",
    "                \"Median (Control)\": np.nan, \"Median (Experimental)\": np.nan,\n",
    "                \"U\": np.nan, \"p\": np.nan, \"Cliff's Δ\": np.nan,\n",
    "                \"Richtung\": \"\", \"Signifikant (α=0.05)\": \"Nein\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        U, p = mannwhitneyu(a, b, alternative=\"two-sided\", method=\"auto\")\n",
    "        delta = cliffs_delta(b, a)  # Δ > 0 ⇒ Experimental > Control\n",
    "\n",
    "        rows.append({\n",
    "            \"Dimension\": dim,\n",
    "            \"Median (Control)\": float(np.median(a)),\n",
    "            \"Median (Experimental)\": float(np.median(b)),\n",
    "            \"U\": float(U),\n",
    "            \"p\": float(p),\n",
    "            \"Cliff's Δ\": float(delta),\n",
    "        })\n",
    "\n",
    "    tests = pd.DataFrame(rows)\n",
    "    for col in [\"Median (Control)\", \"Median (Experimental)\", \"U\", \"p\", \"Cliff's Δ\"]:\n",
    "        if col in tests.columns:\n",
    "            tests[col] = tests[col].round(4)\n",
    "    return tests\n",
    "\n",
    "'''\n",
    "Display the Mann-Whitney-U-Test results\n",
    "'''\n",
    "table_mwu = mwu_test(df, mapping, alpha=0.05)\n",
    "display(table_mwu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
